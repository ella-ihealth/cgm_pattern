{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Nocturnal Hypoglycemia (Moderate) Batch Visualizer\n",
        "\n",
        "This notebook gathers all detections of `nocturnal_hypoglycemia_moderate`,\n",
        "extracts the nightly windows using the recorded sleep window hours, fetches\n",
        "the raw CGM traces, and produces combined and averaged plots to sanity-check\n",
        "the pattern.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "33428b7f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Parameters: edit these values ---\n",
        "pattern_id = \"nocturnal_hypoglycemia_moderate\"\n",
        "#detections_glob = \"/Users/ellaquan/Downloads/cgm_pattern_lib/detection_v1/**/*.json\"\n",
        "detections_glob = \"/Users/ellaquan/Downloads/cgm_pattern_lib/detection_v1/0_detections.json\"\n",
        "patient_filter = None\n",
        "max_examples = None\n",
        "minutes_padding = 30\n",
        "resample_minutes = 5\n",
        "n_clusters = 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e868a29f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "from datetime import datetime, date, time, timedelta, timezone\n",
        "from typing import Any, Dict, Iterable, List, Optional, Tuple\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "repo_root = os.path.abspath(\"..\")\n",
        "if repo_root not in sys.path:\n",
        "    sys.path.insert(0, repo_root)\n",
        "\n",
        "from cgm_patterns.CGM_fetcher import iter_cgm_days\n",
        "from cgm_patterns.models import CGMDay\n",
        "\n",
        "\n",
        "def align_on_nadir(frames, freq_minutes=5):\n",
        "    shifted_data = []\n",
        "    min_shift = float('inf')\n",
        "    max_shift = float('-inf')\n",
        "    for frame in frames:\n",
        "        rel = frame.loc[:, \"relative_minutes\"].to_numpy()\n",
        "        glucose = frame.loc[:, \"glucose_mg_dL\"].to_numpy()\n",
        "        if len(rel) < 3:\n",
        "            continue\n",
        "        nadir_idx = np.argmin(glucose)\n",
        "        nadir_time = rel[nadir_idx]\n",
        "        shifted = rel - nadir_time\n",
        "        order = np.argsort(shifted)\n",
        "        shifted = shifted[order]\n",
        "        glucose = glucose[order]\n",
        "        min_shift = min(min_shift, shifted[0])\n",
        "        max_shift = max(max_shift, shifted[-1])\n",
        "        shifted_data.append((shifted, glucose))\n",
        "    if not shifted_data:\n",
        "        return None, None\n",
        "    length = max(abs(min_shift), abs(max_shift))\n",
        "    grid = np.arange(-length, length + freq_minutes, freq_minutes)\n",
        "    aligned = []\n",
        "    for shifted, glucose in shifted_data:\n",
        "        aligned.append(np.interp(grid, shifted, glucose, left=np.nan, right=np.nan))\n",
        "    return grid, np.vstack(aligned)\n",
        "\n",
        "def summarize_profile(stacked):\n",
        "    median = np.nanmedian(stacked, axis=0)\n",
        "    p10 = np.nanpercentile(stacked, 10, axis=0)\n",
        "    p90 = np.nanpercentile(stacked, 90, axis=0)\n",
        "    count = np.sum(~np.isnan(stacked), axis=0)\n",
        "    return median, p10, p90, count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6a1266d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def _parse_service_date(value: str) -> date:\n",
        "    return datetime.fromisoformat(value).date()\n",
        "\n",
        "\n",
        "def _load_detection_examples(pattern_id: str, paths: Iterable[str], patient_filter: Optional[str] = None) -> List[Dict[str, Any]]:\n",
        "    examples: List[Dict[str, Any]] = []\n",
        "    for path in paths:\n",
        "        try:\n",
        "            payload = json.loads(Path(path).read_text())\n",
        "        except FileNotFoundError:\n",
        "            continue\n",
        "        for patient_id, patient_payload in payload.items():\n",
        "            if patient_filter and patient_id != patient_filter:\n",
        "                continue\n",
        "            detections_by_date = patient_payload.get(\"detections\", {})\n",
        "            for _, detections in detections_by_date.items():\n",
        "                for detection in detections:\n",
        "                    if detection.get(\"pattern_id\") != pattern_id:\n",
        "                        continue\n",
        "                    metrics = detection.get(\"metrics\", {})\n",
        "                    evidence = detection.get(\"evidence\", {})\n",
        "                    for example in evidence.get(\"examples\", []):\n",
        "                        examples.append(\n",
        "                            {\n",
        "                                \"patient_id\": patient_id,\n",
        "                                \"example\": example,\n",
        "                                \"metrics\": metrics,\n",
        "                                \"source_file\": path,\n",
        "                            }\n",
        "                        )\n",
        "    return examples\n",
        "\n",
        "\n",
        "def _fetch_day(patient_id: str, target_date: date) -> Optional[CGMDay]:\n",
        "    start = datetime.combine(target_date, time.min, tzinfo=timezone.utc)\n",
        "    end = start + timedelta(days=1)\n",
        "    for day in iter_cgm_days(patient_id, start=start, end=end):\n",
        "        if day.service_date == target_date:\n",
        "            return day\n",
        "    return None\n",
        "\n",
        "\n",
        "def _day_frame(day: CGMDay) -> pd.DataFrame:\n",
        "    df = day.readings.copy()\n",
        "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
        "    if day.local_timezone:\n",
        "        try:\n",
        "            df[\"local_time\"] = df[\"timestamp\"].dt.tz_convert(day.local_timezone)\n",
        "        except Exception:\n",
        "            df[\"local_time\"] = df[\"timestamp\"]\n",
        "    else:\n",
        "        df[\"local_time\"] = df[\"timestamp\"]\n",
        "    return df.sort_values(\"local_time\")\n",
        "\n",
        "\n",
        "def _window_slice(df: pd.DataFrame, start_hour: float, end_hour: float, padding_minutes: float = 0.0) -> pd.DataFrame:\n",
        "    if df.empty:\n",
        "        return df.iloc[0:0]\n",
        "    base_time = df[\"local_time\"].iloc[0]\n",
        "    midnight = base_time.replace(hour=0, minute=0, second=0, microsecond=0)\n",
        "    start = midnight + timedelta(hours=start_hour) - timedelta(minutes=padding_minutes)\n",
        "    end = midnight + timedelta(hours=end_hour) + timedelta(minutes=padding_minutes)\n",
        "    mask = (df[\"local_time\"] >= start) & (df[\"local_time\"] <= end)\n",
        "    return df.loc[mask].copy()\n",
        "\n",
        "\n",
        "def _relative_minutes(df: pd.DataFrame, start_hour: float) -> pd.Series:\n",
        "    if df.empty:\n",
        "        return pd.Series(dtype=float)\n",
        "    base_time = df[\"local_time\"].iloc[0]\n",
        "    midnight = base_time.replace(hour=0, minute=0, second=0, microsecond=0)\n",
        "    window_start = midnight + timedelta(hours=start_hour)\n",
        "    return (df[\"local_time\"] - window_start).dt.total_seconds() / 60.0\n",
        "\n",
        "\n",
        "def build_average_profile(frames: List[pd.DataFrame], duration_hours: float, freq_minutes: int = 5) -> pd.DataFrame:\n",
        "    if not frames:\n",
        "        return pd.DataFrame()\n",
        "    duration_minutes = int(duration_hours * 60)\n",
        "    grid = np.arange(0, duration_minutes + 1, freq_minutes)\n",
        "    interpolated = []\n",
        "    for frame in frames:\n",
        "        rel = frame.loc[:, \"relative_minutes\"].to_numpy()\n",
        "        glucose = frame.loc[:, \"glucose_mg_dL\"].to_numpy()\n",
        "        if len(rel) < 2:\n",
        "            continue\n",
        "        order = np.argsort(rel)\n",
        "        rel = rel[order]\n",
        "        glucose = glucose[order]\n",
        "        interp = np.interp(grid, rel, glucose, left=np.nan, right=np.nan)\n",
        "        interpolated.append(interp)\n",
        "    if not interpolated:\n",
        "        return pd.DataFrame()\n",
        "    stacked = np.vstack(interpolated)\n",
        "    mean = np.nanmean(stacked, axis=0)\n",
        "    count = np.sum(~np.isnan(stacked), axis=0)\n",
        "    return pd.DataFrame({\n",
        "        \"relative_minutes\": grid,\n",
        "        \"mean_glucose\": mean,\n",
        "        \"sample_count\": count,\n",
        "    })\n",
        "\n",
        "\n",
        "def align_on_nadir(frames, freq_minutes=5):\n",
        "    shifted_data = []\n",
        "    min_shift = float('inf')\n",
        "    max_shift = float('-inf')\n",
        "    for frame in frames:\n",
        "        rel = frame.loc[:, \"relative_minutes\"].to_numpy()\n",
        "        glucose = frame.loc[:, \"glucose_mg_dL\"].to_numpy()\n",
        "        if len(rel) < 3:\n",
        "            continue\n",
        "        nadir_idx = np.argmin(glucose)\n",
        "        nadir_time = rel[nadir_idx]\n",
        "        shifted = rel - nadir_time\n",
        "        order = np.argsort(shifted)\n",
        "        shifted = shifted[order]\n",
        "        glucose = glucose[order]\n",
        "        min_shift = min(min_shift, shifted[0])\n",
        "        max_shift = max(max_shift, shifted[-1])\n",
        "        shifted_data.append((shifted, glucose))\n",
        "    if not shifted_data:\n",
        "        return None, None\n",
        "    grid = np.arange(np.floor(min_shift), np.ceil(max_shift) + freq_minutes, freq_minutes)\n",
        "    aligned = []\n",
        "    for shifted, glucose in shifted_data:\n",
        "        aligned.append(np.interp(grid, shifted, glucose, left=np.nan, right=np.nan))\n",
        "    return grid, np.vstack(aligned)\n",
        "\n",
        "\n",
        "def summarize_profile(stacked):\n",
        "    median = np.nanmedian(stacked, axis=0)\n",
        "    p10 = np.nanpercentile(stacked, 10, axis=0)\n",
        "    p90 = np.nanpercentile(stacked, 90, axis=0)\n",
        "    count = np.sum(~np.isnan(stacked), axis=0)\n",
        "    return median, p10, p90, count\n",
        "\n",
        "\n",
        "def align_on_window_start(frames, duration_hours, freq_minutes=5):\n",
        "    duration_minutes = int(duration_hours * 60)\n",
        "    grid = np.arange(0, duration_minutes + freq_minutes, freq_minutes)\n",
        "    aligned = []\n",
        "    for frame in frames:\n",
        "        rel = frame.loc[:, \"relative_minutes\"].to_numpy()\n",
        "        glucose = frame.loc[:, \"glucose_mg_dL\"].to_numpy()\n",
        "        if len(rel) < 2:\n",
        "            continue\n",
        "        order = np.argsort(rel)\n",
        "        rel = rel[order]\n",
        "        glucose = glucose[order]\n",
        "        aligned.append(np.interp(grid, rel, glucose, left=np.nan, right=np.nan))\n",
        "    if not aligned:\n",
        "        return None, None\n",
        "    return grid, np.vstack(aligned)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "89f33046",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 50 examples so far...\n",
            "Processed 100 examples so far...\n",
            "Processed 150 examples so far...\n",
            "Processed 200 examples so far...\n",
            "Collected 245 windows from 245 detections.\n"
          ]
        }
      ],
      "source": [
        "detection_paths = glob.glob(detections_glob, recursive=True)\n",
        "examples = _load_detection_examples(pattern_id, detection_paths, patient_filter=patient_filter)\n",
        "if not examples:\n",
        "    raise ValueError(\"No detection examples found for the specified parameters.\")\n",
        "if max_examples is not None:\n",
        "    examples = examples[:max_examples]\n",
        "window_frames: List[pd.DataFrame] = []\n",
        "window_metadata: List[dict] = []\n",
        "window_start_hour = None\n",
        "window_end_hour = None\n",
        "for idx, payload in enumerate(examples, start=1):\n",
        "    patient_id = payload[\"patient_id\"]\n",
        "    example = payload[\"example\"]\n",
        "    metrics = payload.get(\"metrics\", {})\n",
        "    start_hour = float(metrics.get(\"sleep_window_start\", 0.0))\n",
        "    end_hour = float(metrics.get(\"sleep_window_end\", 6.0))\n",
        "    if window_start_hour is None:\n",
        "        window_start_hour = start_hour\n",
        "        window_end_hour = end_hour\n",
        "    service_date = _parse_service_date(example[\"service_date\"])\n",
        "    day = _fetch_day(patient_id, service_date)\n",
        "    if day is None:\n",
        "        print(f\"No CGM day found for {patient_id} on {service_date}\")\n",
        "        continue\n",
        "    frame = _day_frame(day)\n",
        "    window_df = _window_slice(frame, start_hour, end_hour, padding_minutes=minutes_padding)\n",
        "    if window_df.empty:\n",
        "        print(f\"Empty window for {patient_id} on {service_date}\")\n",
        "        continue\n",
        "    window_df[\"relative_minutes\"] = _relative_minutes(window_df, start_hour)\n",
        "    window_df[\"glucose_mg_dL\"] = pd.to_numeric(window_df[\"glucose_mg_dL\"], errors=\"coerce\")\n",
        "    window_df = window_df.dropna(subset=[\"glucose_mg_dL\", \"relative_minutes\"])\n",
        "    if window_df.empty:\n",
        "        continue\n",
        "    window_frames.append(window_df[[\"relative_minutes\", \"glucose_mg_dL\"]])\n",
        "    window_metadata.append({\n",
        "        \"patient_id\": patient_id,\n",
        "        \"service_date\": service_date,\n",
        "        \"minutes_low\": example.get(\"minutes_low\"),\n",
        "        \"lowest_glucose\": example.get(\"lowest_glucose\"),\n",
        "        \"start_hour\": start_hour,\n",
        "        \"end_hour\": end_hour,\n",
        "    })\n",
        "    if idx % 50 == 0:\n",
        "        print(f\"Processed {idx} examples so far...\")\n",
        "print(f\"Collected {len(window_frames)} windows from {len(examples)} detections.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e80da8ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import plotly.io as pio\n",
        "pio.renderers.default = \"browser\"\n",
        "if window_frames and window_start_hour is not None and window_end_hour is not None:\n",
        "    combined_df = pd.concat(window_frames, ignore_index=True)\n",
        "    fig_overlay = go.Figure()\n",
        "    for frame in window_frames:\n",
        "        fig_overlay.add_trace(\n",
        "            go.Scatter(\n",
        "                x=frame[\"relative_minutes\"],\n",
        "                y=frame[\"glucose_mg_dL\"],\n",
        "                mode=\"lines\",\n",
        "                line=dict(width=1, color=\"rgba(0, 0, 255, 0.1)\"),\n",
        "                showlegend=False,\n",
        "            )\n",
        "        )\n",
        "    fig_overlay.add_hrect(y0=0, y1=70, fillcolor=\"red\", opacity=0.1, line_width=0)\n",
        "    fig_overlay.update_layout(\n",
        "        title=\"All nocturnal hypoglycemia windows\",\n",
        "        xaxis_title=\"Minutes since sleep window start\",\n",
        "        yaxis_title=\"Glucose (mg/dL)\",\n",
        "    )\n",
        "    fig_overlay.show()\n",
        "\n",
        "    fig_hist = go.Figure()\n",
        "    fig_hist.add_trace(\n",
        "        go.Histogram(\n",
        "            x=combined_df[\"relative_minutes\"],\n",
        "            nbinsx=60,\n",
        "            marker_color=\"rgba(0, 0, 255, 0.4)\",\n",
        "        )\n",
        "    )\n",
        "    fig_hist.update_layout(\n",
        "        title=\"Distribution of minutes since sleep window start\",\n",
        "        xaxis_title=\"Minutes since window start\",\n",
        "        yaxis_title=\"Count\",\n",
        "    )\n",
        "    fig_hist.show()\n",
        "\n",
        "    fig_scatter = go.Figure(\n",
        "        data=go.Scattergl(\n",
        "            x=combined_df[\"relative_minutes\"],\n",
        "            y=combined_df[\"glucose_mg_dL\"],\n",
        "            mode=\"markers\",\n",
        "            marker=dict(size=3, opacity=0.1, color=\"blue\"),\n",
        "        )\n",
        "    )\n",
        "    fig_scatter.add_hrect(y0=0, y1=70, fillcolor=\"red\", opacity=0.1, line_width=0)\n",
        "    fig_scatter.update_layout(\n",
        "        title=\"Scatter distribution of nocturnal hypoglycemia windows\",\n",
        "        xaxis_title=\"Minutes since window start\",\n",
        "        yaxis_title=\"Glucose (mg/dL)\",\n",
        "    )\n",
        "    fig_scatter.show()\n",
        "\n",
        "    fig_overlay_time = go.Figure()\n",
        "    for frame in window_frames:\n",
        "        fig_overlay_time.add_trace(\n",
        "            go.Scatter(\n",
        "                x=window_start_hour + frame[\"relative_minutes\"] / 60.0,\n",
        "                y=frame[\"glucose_mg_dL\"]\n",
        "                ,\n",
        "                mode=\"lines\",\n",
        "                line=dict(width=1, color=\"rgba(0, 0, 255, 0.1)\"),\n",
        "                showlegend=False,\n",
        "            )\n",
        "        )\n",
        "    fig_overlay_time.add_hrect(y0=0, y1=70, fillcolor=\"red\", opacity=0.1, line_width=0)\n",
        "    tickhours = [window_start_hour + offset / 60.0 for offset in range(0, int((window_end_hour - window_start_hour) * 60) + 1, 60)]\n",
        "    ticklabels = [f\"{int(hour % 24):02d}:00\" for hour in tickhours]\n",
        "    fig_overlay_time.update_layout(\n",
        "        title=\"All nocturnal hypoglycemia windows | Clock time\",\n",
        "        xaxis_title=\"Clock time (hours)\",\n",
        "        xaxis=dict(tickmode=\"array\", tickvals=tickhours, ticktext=ticklabels),\n",
        "        yaxis_title=\"Glucose (mg/dL)\",\n",
        "    )\n",
        "    fig_overlay_time.show()\n",
        "\n",
        "    fig_hist_time = go.Figure()\n",
        "    fig_hist_time.add_trace(\n",
        "        go.Histogram(\n",
        "            x=window_start_hour + combined_df[\"relative_minutes\"] / 60.0,\n",
        "            nbinsx=60,\n",
        "            marker_color=\"rgba(0, 0, 255, 0.4)\",\n",
        "        )\n",
        "    )\n",
        "    fig_hist_time.update_layout(\n",
        "        title=\"Distribution of clock time\",\n",
        "        xaxis_title=\"Clock time (hours)\",\n",
        "        yaxis_title=\"Count\",\n",
        "    )\n",
        "    fig_hist_time.show()\n",
        "else:\n",
        "    print(\"No windows available for overlay plot.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "177fbeb6",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'window_frames' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mwindow_frames\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m window_start_hour \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m window_end_hour \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      2\u001b[39m     duration_hours = window_end_hour - window_start_hour\n\u001b[32m      3\u001b[39m     cluster_metrics = []\n",
            "\u001b[31mNameError\u001b[39m: name 'window_frames' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "if window_frames and window_start_hour is not None and window_end_hour is not None:\n",
        "    duration_hours = window_end_hour - window_start_hour\n",
        "    cluster_metrics = []\n",
        "    metadata_df = pd.DataFrame(window_metadata) if window_metadata else pd.DataFrame()\n",
        "\n",
        "    grid_nadir, stacked_nadir = align_on_nadir(window_frames, freq_minutes=resample_minutes)\n",
        "    if grid_nadir is None:\n",
        "        print(\"No nadir-aligned data available for clustering.\")\n",
        "    else:\n",
        "        clean_nadir = np.where(np.isnan(stacked_nadir), np.nanmedian(stacked_nadir, axis=0), stacked_nadir)\n",
        "        clean_nadir = clean_nadir[:, ~np.all(np.isnan(clean_nadir), axis=0)]\n",
        "        if clean_nadir.size == 0:\n",
        "            print(\"All nadir-aligned columns are NaN; skipping nadir clustering.\")\n",
        "        else:\n",
        "            col_mean_nadir = np.nanmean(clean_nadir, axis=0)\n",
        "            clean_nadir = np.nan_to_num(clean_nadir, nan=col_mean_nadir)\n",
        "            if clean_nadir.shape[0] >= n_clusters and not np.all(clean_nadir == clean_nadir[0]):\n",
        "                labels_nadir = KMeans(n_clusters=n_clusters, random_state=42).fit_predict(clean_nadir)\n",
        "                print(f\"Nadir cluster assignments: {labels_nadir[:20]} ...\")\n",
        "                for cluster_id in range(n_clusters):\n",
        "                    subset = stacked_nadir[labels_nadir == cluster_id]\n",
        "                    if subset.size == 0:\n",
        "                        continue\n",
        "                    median, p10, p90, count = summarize_profile(subset)\n",
        "                    fig = go.Figure()\n",
        "                    fig.add_trace(go.Scatter(x=grid_nadir, y=median, mode='lines', name=f'Cluster {cluster_id + 1} median'))\n",
        "                    fig.add_trace(go.Scatter(x=grid_nadir, y=p90, mode='lines', name='90th percentile', line=dict(dash='dash')))\n",
        "                    fig.add_trace(go.Scatter(x=grid_nadir, y=p10, mode='lines', name='10th percentile', line=dict(dash='dash')))\n",
        "                    fig.add_hrect(y0=0, y1=70, fillcolor='red', opacity=0.1, line_width=0)\n",
        "                    fig.update_layout(\n",
        "                        title=f\"Nadir-aligned nocturnal hypoglycemia | Cluster {cluster_id + 1} (n={subset.shape[0]})\",\n",
        "                        xaxis_title=\"Minutes relative to nadir\",\n",
        "                        yaxis_title=\"Glucose (mg/dL)\",\n",
        "                    )\n",
        "                    fig.show()\n",
        "                    cluster_metrics.append({\"alignment\": \"nadir\", \"cluster\": cluster_id + 1, \"count\": subset.shape[0]})\n",
        "                    if not metadata_df.empty:\n",
        "                        idxs = np.where(labels_nadir == cluster_id)[0]\n",
        "                        cluster_metrics[-1].update({\n",
        "                            \"minutes_low_mean\": metadata_df.iloc[idxs]['minutes_low'].mean(),\n",
        "                            \"lowest_glucose_mean\": metadata_df.iloc[idxs]['lowest_glucose'].mean(),\n",
        "                        })\n",
        "            else:\n",
        "                print(\"Not enough nadir-aligned data for clustering.\")\n",
        "\n",
        "    grid_start, stacked_start = align_on_window_start(window_frames, duration_hours, freq_minutes=resample_minutes)\n",
        "    if grid_start is None:\n",
        "        print(\"No window-start aligned data available for clustering.\")\n",
        "    else:\n",
        "        clean_start = np.where(np.isnan(stacked_start), np.nanmedian(stacked_start, axis=0), stacked_start)\n",
        "        clean_start = clean_start[:, ~np.all(np.isnan(clean_start), axis=0)]\n",
        "        if clean_start.size == 0:\n",
        "            print(\"All window-start columns are NaN; skipping window-start clustering.\")\n",
        "        else:\n",
        "            col_mean_start = np.nanmean(clean_start, axis=0)\n",
        "            clean_start = np.nan_to_num(clean_start, nan=col_mean_start)\n",
        "            if clean_start.shape[0] >= n_clusters and not np.all(clean_start == clean_start[0]):\n",
        "                labels_start = KMeans(n_clusters=n_clusters, random_state=42).fit_predict(clean_start)\n",
        "                print(f\"Window-start cluster assignments: {labels_start[:20]} ...\")\n",
        "                for cluster_id in range(n_clusters):\n",
        "                    subset = stacked_start[labels_start == cluster_id]\n",
        "                    if subset.size == 0:\n",
        "                        continue\n",
        "                    median, p10, p90, count = summarize_profile(subset)\n",
        "                    fig = go.Figure()\n",
        "                    fig.add_trace(go.Scatter(x=grid_start, y=median, mode='lines', name=f'Cluster {cluster_id + 1} median'))\n",
        "                    fig.add_trace(go.Scatter(x=grid_start, y=p90, mode='lines', name='90th percentile', line=dict(dash='dash')))\n",
        "                    fig.add_trace(go.Scatter(x=grid_start, y=p10, mode='lines', name='10th percentile', line=dict(dash='dash')))\n",
        "                    fig.add_hrect(y0=0, y1=70, fillcolor='red', opacity=0.1, line_width=0)\n",
        "                    fig.update_layout(\n",
        "                        title=f\"Window-start aligned nocturnal hypoglycemia | Cluster {cluster_id + 1} (n={subset.shape[0]})\",\n",
        "                        xaxis_title=\"Minutes since window start\",\n",
        "                        yaxis_title=\"Glucose (mg/dL)\",\n",
        "                    )\n",
        "                    fig.show()\n",
        "                    cluster_metrics.append({\"alignment\": \"window_start\", \"cluster\": cluster_id + 1, \"count\": subset.shape[0]})\n",
        "                    if not metadata_df.empty:\n",
        "                        idxs = np.where(labels_start == cluster_id)[0]\n",
        "                        cluster_metrics[-1].update({\n",
        "                            \"minutes_low_mean\": metadata_df.iloc[idxs]['minutes_low'].mean(),\n",
        "                            \"lowest_glucose_mean\": metadata_df.iloc[idxs]['lowest_glucose'].mean(),\n",
        "                        })\n",
        "            else:\n",
        "                print(\"Not enough window-start data for clustering.\")\n",
        "\n",
        "    if cluster_metrics:\n",
        "        cluster_summary_df = pd.DataFrame(cluster_metrics)\n",
        "        print(\"Cluster summary (counts and average metrics):\")\n",
        "        display(cluster_summary_df)\n",
        "else:\n",
        "    print(\"No frames available for clustering.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53b55544",
      "metadata": {},
      "outputs": [],
      "source": [
        "if window_frames and window_start_hour is not None and window_end_hour is not None:\n",
        "    duration_hours = window_end_hour - window_start_hour\n",
        "    metadata_df = pd.DataFrame(window_metadata) if 'window_metadata' in globals() else pd.DataFrame()\n",
        "    cluster_metrics = []\n",
        "    grid_nadir, stacked_nadir = align_on_nadir(window_frames, freq_minutes=resample_minutes)\n",
        "    if grid_nadir is None:\n",
        "        print(\"No nadir-aligned data available for clustering.\")\n",
        "    else:\n",
        "        clean_nadir = np.where(np.isnan(stacked_nadir), np.nanmedian(stacked_nadir, axis=0), stacked_nadir)\n",
        "        clean_nadir = clean_nadir[:, ~np.all(np.isnan(clean_nadir), axis=0)]\n",
        "        if clean_nadir.size == 0:\n",
        "            print(\"All nadir-aligned columns are NaN; skipping nadir clustering.\")\n",
        "        else:\n",
        "            col_mean_nadir = np.nanmean(clean_nadir, axis=0)\n",
        "            clean_nadir = np.nan_to_num(clean_nadir, nan=col_mean_nadir)\n",
        "            if clean_nadir.shape[0] >= n_clusters and not np.all(clean_nadir == clean_nadir[0]):\n",
        "                labels_nadir = KMeans(n_clusters=n_clusters, random_state=42).fit_predict(clean_nadir)\n",
        "                print(f\"Nadir cluster assignments: {labels_nadir[:20]} ...\")\n",
        "                for cluster_id in range(n_clusters):\n",
        "                    idxs = np.where(labels_nadir == cluster_id)[0]\n",
        "                    subset = stacked_nadir[idxs]\n",
        "                    if subset.size == 0:\n",
        "                        continue\n",
        "                    median, p10, p90, count = summarize_profile(subset)\n",
        "                    fig = go.Figure()\n",
        "                    fig.add_trace(go.Scatter(x=grid_nadir, y=median, mode='lines', name=f'Cluster {cluster_id + 1} median'))\n",
        "                    fig.add_trace(go.Scatter(x=grid_nadir, y=p90, mode='lines', name='90th percentile', line=dict(dash='dash')))\n",
        "                    fig.add_trace(go.Scatter(x=grid_nadir, y=p10, mode='lines', name='10th percentile', line=dict(dash='dash')))\n",
        "                    fig.add_hrect(y0=0, y1=70, fillcolor='red', opacity=0.1, line_width=0)\n",
        "                    fig.update_layout(\n",
        "                        title=f\"Nadir-aligned nocturnal hypoglycemia | Cluster {cluster_id + 1} (n={subset.shape[0]})\",\n",
        "                        xaxis_title=\"Minutes relative to nadir\",\n",
        "                        yaxis_title=\"Glucose (mg/dL)\",\n",
        "                    )\n",
        "                    fig.show()\n",
        "                    metrics = {\"alignment\": \"nadir\", \"cluster\": cluster_id + 1, \"count\": subset.shape[0]}\n",
        "                    if not metadata_df.empty:\n",
        "                        metrics[\"minutes_low_mean\"] = metadata_df.iloc[idxs]['minutes_low'].mean()\n",
        "                        metrics[\"lowest_glucose_mean\"] = metadata_df.iloc[idxs]['lowest_glucose'].mean()\n",
        "                    cluster_metrics.append(metrics)\n",
        "            else:\n",
        "                print(\"Not enough nadir-aligned data for clustering.\")\n",
        "    grid_start, stacked_start = align_on_window_start(window_frames, duration_hours, freq_minutes=resample_minutes)\n",
        "    if grid_start is None:\n",
        "        print(\"No window-start aligned data available for clustering.\")\n",
        "    else:\n",
        "        clean_start = np.where(np.isnan(stacked_start), np.nanmedian(stacked_start, axis=0), stacked_start)\n",
        "        clean_start = clean_start[:, ~np.all(np.isnan(clean_start), axis=0)]\n",
        "        if clean_start.size == 0:\n",
        "            print(\"All window-start columns are NaN; skipping window-start clustering.\")\n",
        "        else:\n",
        "            col_mean_start = np.nanmean(clean_start, axis=0)\n",
        "            clean_start = np.nan_to_num(clean_start, nan=col_mean_start)\n",
        "            if clean_start.shape[0] >= n_clusters and not np.all(clean_start == clean_start[0]):\n",
        "                labels_start = KMeans(n_clusters=n_clusters, random_state=42).fit_predict(clean_start)\n",
        "                print(f\"Window-start cluster assignments: {labels_start[:20]} ...\")\n",
        "                for cluster_id in range(n_clusters):\n",
        "                    idxs = np.where(labels_start == cluster_id)[0]\n",
        "                    subset = stacked_start[idxs]\n",
        "                    if subset.size == 0:\n",
        "                        continue\n",
        "                    median, p10, p90, count = summarize_profile(subset)\n",
        "                    fig = go.Figure()\n",
        "                    fig.add_trace(go.Scatter(x=grid_start, y=median, mode='lines', name=f'Cluster {cluster_id + 1} median'))\n",
        "                    fig.add_trace(go.Scatter(x=grid_start, y=p90, mode='lines', name='90th percentile', line=dict(dash='dash')))\n",
        "                    fig.add_trace(go.Scatter(x=grid_start, y=p10, mode='lines', name='10th percentile', line=dict(dash='dash')))\n",
        "                    fig.add_hrect(y0=0, y1=70, fillcolor='red', opacity=0.1, line_width=0)\n",
        "                    fig.update_layout(\n",
        "                        title=f\"Window-start aligned nocturnal hypoglycemia | Cluster {cluster_id + 1} (n={subset.shape[0]})\",\n",
        "                        xaxis_title=\"Minutes since window start\",\n",
        "                        yaxis_title=\"Glucose (mg/dL)\",\n",
        "                    )\n",
        "                    fig.show()\n",
        "                    metrics = {\"alignment\": \"window_start\", \"cluster\": cluster_id + 1, \"count\": subset.shape[0]}\n",
        "                    if not metadata_df.empty:\n",
        "                        metrics[\"minutes_low_mean\"] = metadata_df.iloc[idxs]['minutes_low'].mean()\n",
        "                        metrics[\"lowest_glucose_mean\"] = metadata_df.iloc[idxs]['lowest_glucose'].mean()\n",
        "                    cluster_metrics.append(metrics)\n",
        "            else:\n",
        "                print(\"Not enough window-start data for clustering.\")\n",
        "    if cluster_metrics:\n",
        "        cluster_summary_df = pd.DataFrame(cluster_metrics)\n",
        "        display(cluster_summary_df)\n",
        "    else:\n",
        "        print(\"No cluster metrics computed.\")\n",
        "else:\n",
        "    print(\"No frames available for clustering.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85f97d74",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "if 'cluster_summary_df' in globals():\n",
        "    print(\"Counts by alignment and cluster:\")\n",
        "    display(cluster_summary_df.groupby(['alignment', 'cluster'])['count'].sum())\n",
        "else:\n",
        "    print(\"No cluster summary available.\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "agent311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
